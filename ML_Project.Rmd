---
title: "ML Project"
author: "JL Apodaca"
date: "Sunday, January 25, 2015"
output: html_document
---
## Loading  data, assuming already downloaded to working directory from 
#### https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
#### https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

```{r}
library(caret)
training<-read.csv("projtraining.csv", na.strings= c('NA','','#DIV/0!'))


testing<-read.csv("projtesting.csv",na.strings= c('NA','','#DIV/0!'))
```

## Eliminating variables that do not contribute to  model accuracy
### Lets see which columsn are near zero value, so we can eliminate those from the analysis

```{r}
nsv<-nearZeroVar(training,saveMetrics=TRUE)
removezv<-which(nsv$nzv)
```

### The following columns are not considered as predictors since they are basically stamps and labels
```{r}
stamps<-c(1,3,4,5)
```

### Which columns are mostly NA and do not produce much signal
```{r}
NAindex<-((sapply(1:ncol(training), function(x) {(sum(is.na(training[,x]))>950)})))
NAindex<-which(NAindex)
indexwNA<-union(removezv,stamps)
indexwoNA<-union(indexwNA,NAindex)
```


## Creating k folds
```{r}
set.seed(32323)
foldstrain<-createFolds(y=training$classe,k=10, list=TRUE, returnTrain = TRUE)
```


## Model and variable selection
### We will do an initial approach with Classification and Regression trees model (rpart)
### In order to select the best configuration with a fast method
### using NA columns, with no preprocessing

```{r}
trainingbase<-training[foldstrain[[1]],]
testingbase<-training[-foldstrain[[1]],]
modFitBase<-train(classe ~ ., method='rpart', data=trainingbase[,-indexwNA])
print(modFitBase)
```

### We can see that the accuracy is very low. We should eliminate mostly NA variables to 
### improve accuracy.

```{r}
trainingnoNA<-training[foldstrain[[2]],]
testingnoNA<-training[-foldstrain[[2]],]
modFitnoNA<-train(classe ~ ., method='rpart', data=trainingnoNA[,-indexwoNA])
confusionMatrix(testingnoNA$classe,predict(modFitnoNA,testingnoNA[,-indexwoNA]))
```


###Accuracy is up to 59% in sample, and 57% out of sample, but still pretty low. Lets try 
### centering and scaling the remaining variables.

```{r}
traininscale<-training[foldstrain[[3]],]
testingscale<-training[-foldstrain[[3]],]
modFitscale<-train(classe ~ ., method='rpart', data=traininscale[,-indexwoNA],
                   preProcess=c('center','scale'))
confusionMatrix(testingscale$classe,predict(modFitscale, newdata= testingscale[,-indexwoNA]))
```

### We will stick to training with 55 variable, no scaling, or centering.
### Lets see if a method such as Random Forests with PCA improves accuracy

```{r, eval=FALSE}
trainingRF<-training[foldstrain[[5]],]
testingRF<-training[-foldstrain[[5]],]
modFitRF<-train(classe ~ ., method='rf', data=trainingRF[,-indexwoNA],preProcess='pca')
confusionMatrix(testingRF$classe,predict(modFitRF, newdata= testingRF[,-indexwoNA]))
```

### Note: The previous code with Random Forest Model and PCA pre-processing timed out and I was 
### never able to run it (unable to allocate vector size). The selected model then will be modFitnoNA

## Expected out of sample error
### According to the selected model, the expected out of sample error would be 43%, or 57% accuracy

```{r}
confusionMatrix(testingnoNA$classe,predict(modFitnoNA,testingnoNA[,-indexwoNA]))
```

## Finally, the predictions for the 20 cases to test are obtained as follows

```{r}

finalnames<-names(training[,-indexwoNA])
finalnames<-finalnames[1:(length(finalnames)-1)]
predictions<-predict(modFitnoNA, newdata= testing[,finalnames])

```

